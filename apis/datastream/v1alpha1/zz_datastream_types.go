// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AzureConnectorInitParameters struct {

	// Access keys associated with Azure Storage account
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// Specifies the Azure Storage account name
	AccountName *string `json:"accountName,omitempty" tf:"account_name,omitempty"`

	// Specifies the Azure Storage container name
	ContainerName *string `json:"containerName,omitempty" tf:"container_name,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Azure Storage container where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`
}

type AzureConnectorObservation struct {

	// Specifies the Azure Storage account name
	AccountName *string `json:"accountName,omitempty" tf:"account_name,omitempty"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Specifies the Azure Storage container name
	ContainerName *string `json:"containerName,omitempty" tf:"container_name,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Azure Storage container where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`
}

type AzureConnectorParameters struct {

	// Access keys associated with Azure Storage account
	// +kubebuilder:validation:Optional
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// Specifies the Azure Storage account name
	// +kubebuilder:validation:Optional
	AccountName *string `json:"accountName" tf:"account_name,omitempty"`

	// Specifies the Azure Storage container name
	// +kubebuilder:validation:Optional
	ContainerName *string `json:"containerName" tf:"container_name,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The path to the folder within Azure Storage container where logs will be stored
	// +kubebuilder:validation:Optional
	Path *string `json:"path" tf:"path,omitempty"`
}

type DatadogConnectorInitParameters struct {

	// The API key associated with Datadog account
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Datadog endpoint where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The service of the Datadog connector
	Service *string `json:"service,omitempty" tf:"service,omitempty"`

	// The source of the Datadog connector
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The tags of the Datadog connector
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type DatadogConnectorObservation struct {

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Datadog endpoint where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The service of the Datadog connector
	Service *string `json:"service,omitempty" tf:"service,omitempty"`

	// The source of the Datadog connector
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The tags of the Datadog connector
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type DatadogConnectorParameters struct {

	// The API key associated with Datadog account
	// +kubebuilder:validation:Optional
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// Indicates whether the logs should be compressed
	// +kubebuilder:validation:Optional
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The Datadog endpoint where logs will be stored
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`

	// The service of the Datadog connector
	// +kubebuilder:validation:Optional
	Service *string `json:"service,omitempty" tf:"service,omitempty"`

	// The source of the Datadog connector
	// +kubebuilder:validation:Optional
	Source *string `json:"source,omitempty" tf:"source,omitempty"`

	// The tags of the Datadog connector
	// +kubebuilder:validation:Optional
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type DatastreamInitParameters struct {

	// Defining if stream should be active or not
	Active *bool `json:"active,omitempty" tf:"active,omitempty"`

	AzureConnector []AzureConnectorInitParameters `json:"azureConnector,omitempty" tf:"azure_connector,omitempty"`

	// Identifies if stream needs to collect midgress data
	CollectMidgress *bool `json:"collectMidgress,omitempty" tf:"collect_midgress,omitempty"`

	// Identifies the contract that has access to the product
	ContractID *string `json:"contractId,omitempty" tf:"contract_id,omitempty"`

	DatadogConnector []DatadogConnectorInitParameters `json:"datadogConnector,omitempty" tf:"datadog_connector,omitempty"`

	// A list of data set fields selected from the associated template that the stream monitors in logs. The order of the identifiers define how the value for these fields appear in the log lines
	DatasetFields []*float64 `json:"datasetFields,omitempty" tf:"dataset_fields,omitempty"`

	// Provides information about the configuration related to logs (format, file names, delivery frequency)
	DeliveryConfiguration []DeliveryConfigurationInitParameters `json:"deliveryConfiguration,omitempty" tf:"delivery_configuration,omitempty"`

	ElasticsearchConnector []ElasticsearchConnectorInitParameters `json:"elasticsearchConnector,omitempty" tf:"elasticsearch_connector,omitempty"`

	GcsConnector []GcsConnectorInitParameters `json:"gcsConnector,omitempty" tf:"gcs_connector,omitempty"`

	// Identifies the group that has access to the product and for which the stream configuration was created
	GroupID *string `json:"groupId,omitempty" tf:"group_id,omitempty"`

	HTTPSConnector []HTTPSConnectorInitParameters `json:"httpsConnector,omitempty" tf:"https_connector,omitempty"`

	LogglyConnector []LogglyConnectorInitParameters `json:"logglyConnector,omitempty" tf:"loggly_connector,omitempty"`

	NewRelicConnector []NewRelicConnectorInitParameters `json:"newRelicConnector,omitempty" tf:"new_relic_connector,omitempty"`

	// List of email addresses where the system sends notifications about activations and deactivations of the stream
	NotificationEmails []*string `json:"notificationEmails,omitempty" tf:"notification_emails,omitempty"`

	OracleConnector []OracleConnectorInitParameters `json:"oracleConnector,omitempty" tf:"oracle_connector,omitempty"`

	// Identifies the properties monitored in the stream
	Properties []*string `json:"properties,omitempty" tf:"properties,omitempty"`

	S3Connector []S3ConnectorInitParameters `json:"s3Connector,omitempty" tf:"s3_connector,omitempty"`

	SplunkConnector []SplunkConnectorInitParameters `json:"splunkConnector,omitempty" tf:"splunk_connector,omitempty"`

	// The name of the stream
	StreamName *string `json:"streamName,omitempty" tf:"stream_name,omitempty"`

	SumologicConnector []SumologicConnectorInitParameters `json:"sumologicConnector,omitempty" tf:"sumologic_connector,omitempty"`
}

type DatastreamObservation struct {

	// Defining if stream should be active or not
	Active *bool `json:"active,omitempty" tf:"active,omitempty"`

	AzureConnector []AzureConnectorObservation `json:"azureConnector,omitempty" tf:"azure_connector,omitempty"`

	// Identifies if stream needs to collect midgress data
	CollectMidgress *bool `json:"collectMidgress,omitempty" tf:"collect_midgress,omitempty"`

	// Identifies the contract that has access to the product
	ContractID *string `json:"contractId,omitempty" tf:"contract_id,omitempty"`

	// The username who created the stream
	CreatedBy *string `json:"createdBy,omitempty" tf:"created_by,omitempty"`

	// The date and time when the stream was created
	CreatedDate *string `json:"createdDate,omitempty" tf:"created_date,omitempty"`

	DatadogConnector []DatadogConnectorObservation `json:"datadogConnector,omitempty" tf:"datadog_connector,omitempty"`

	// A list of data set fields selected from the associated template that the stream monitors in logs. The order of the identifiers define how the value for these fields appear in the log lines
	DatasetFields []*float64 `json:"datasetFields,omitempty" tf:"dataset_fields,omitempty"`

	// Provides information about the configuration related to logs (format, file names, delivery frequency)
	DeliveryConfiguration []DeliveryConfigurationObservation `json:"deliveryConfiguration,omitempty" tf:"delivery_configuration,omitempty"`

	ElasticsearchConnector []ElasticsearchConnectorObservation `json:"elasticsearchConnector,omitempty" tf:"elasticsearch_connector,omitempty"`

	GcsConnector []GcsConnectorObservation `json:"gcsConnector,omitempty" tf:"gcs_connector,omitempty"`

	// Identifies the group that has access to the product and for which the stream configuration was created
	GroupID *string `json:"groupId,omitempty" tf:"group_id,omitempty"`

	HTTPSConnector []HTTPSConnectorObservation `json:"httpsConnector,omitempty" tf:"https_connector,omitempty"`

	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// Identifies the latest active configuration version of the stream
	LatestVersion *float64 `json:"latestVersion,omitempty" tf:"latest_version,omitempty"`

	LogglyConnector []LogglyConnectorObservation `json:"logglyConnector,omitempty" tf:"loggly_connector,omitempty"`

	// The username who modified the stream
	ModifiedBy *string `json:"modifiedBy,omitempty" tf:"modified_by,omitempty"`

	// The date and time when the stream was modified
	ModifiedDate *string `json:"modifiedDate,omitempty" tf:"modified_date,omitempty"`

	NewRelicConnector []NewRelicConnectorObservation `json:"newRelicConnector,omitempty" tf:"new_relic_connector,omitempty"`

	// List of email addresses where the system sends notifications about activations and deactivations of the stream
	NotificationEmails []*string `json:"notificationEmails,omitempty" tf:"notification_emails,omitempty"`

	OracleConnector []OracleConnectorObservation `json:"oracleConnector,omitempty" tf:"oracle_connector,omitempty"`

	// The configuration in JSON format that can be copy-pasted into PAPI configuration to enable datastream behavior
	PapiJSON *string `json:"papiJson,omitempty" tf:"papi_json,omitempty"`

	// The ID of the product for which the stream was created
	ProductID *string `json:"productId,omitempty" tf:"product_id,omitempty"`

	// Identifies the properties monitored in the stream
	Properties []*string `json:"properties,omitempty" tf:"properties,omitempty"`

	S3Connector []S3ConnectorObservation `json:"s3Connector,omitempty" tf:"s3_connector,omitempty"`

	SplunkConnector []SplunkConnectorObservation `json:"splunkConnector,omitempty" tf:"splunk_connector,omitempty"`

	// The name of the stream
	StreamName *string `json:"streamName,omitempty" tf:"stream_name,omitempty"`

	// Identifies the configuration version of the stream
	StreamVersion *float64 `json:"streamVersion,omitempty" tf:"stream_version,omitempty"`

	SumologicConnector []SumologicConnectorObservation `json:"sumologicConnector,omitempty" tf:"sumologic_connector,omitempty"`
}

type DatastreamParameters struct {

	// Defining if stream should be active or not
	// +kubebuilder:validation:Optional
	Active *bool `json:"active,omitempty" tf:"active,omitempty"`

	// +kubebuilder:validation:Optional
	AzureConnector []AzureConnectorParameters `json:"azureConnector,omitempty" tf:"azure_connector,omitempty"`

	// Identifies if stream needs to collect midgress data
	// +kubebuilder:validation:Optional
	CollectMidgress *bool `json:"collectMidgress,omitempty" tf:"collect_midgress,omitempty"`

	// Identifies the contract that has access to the product
	// +kubebuilder:validation:Optional
	ContractID *string `json:"contractId,omitempty" tf:"contract_id,omitempty"`

	// +kubebuilder:validation:Optional
	DatadogConnector []DatadogConnectorParameters `json:"datadogConnector,omitempty" tf:"datadog_connector,omitempty"`

	// A list of data set fields selected from the associated template that the stream monitors in logs. The order of the identifiers define how the value for these fields appear in the log lines
	// +kubebuilder:validation:Optional
	DatasetFields []*float64 `json:"datasetFields,omitempty" tf:"dataset_fields,omitempty"`

	// Provides information about the configuration related to logs (format, file names, delivery frequency)
	// +kubebuilder:validation:Optional
	DeliveryConfiguration []DeliveryConfigurationParameters `json:"deliveryConfiguration,omitempty" tf:"delivery_configuration,omitempty"`

	// +kubebuilder:validation:Optional
	ElasticsearchConnector []ElasticsearchConnectorParameters `json:"elasticsearchConnector,omitempty" tf:"elasticsearch_connector,omitempty"`

	// +kubebuilder:validation:Optional
	GcsConnector []GcsConnectorParameters `json:"gcsConnector,omitempty" tf:"gcs_connector,omitempty"`

	// Identifies the group that has access to the product and for which the stream configuration was created
	// +kubebuilder:validation:Optional
	GroupID *string `json:"groupId,omitempty" tf:"group_id,omitempty"`

	// +kubebuilder:validation:Optional
	HTTPSConnector []HTTPSConnectorParameters `json:"httpsConnector,omitempty" tf:"https_connector,omitempty"`

	// +kubebuilder:validation:Optional
	LogglyConnector []LogglyConnectorParameters `json:"logglyConnector,omitempty" tf:"loggly_connector,omitempty"`

	// +kubebuilder:validation:Optional
	NewRelicConnector []NewRelicConnectorParameters `json:"newRelicConnector,omitempty" tf:"new_relic_connector,omitempty"`

	// List of email addresses where the system sends notifications about activations and deactivations of the stream
	// +kubebuilder:validation:Optional
	NotificationEmails []*string `json:"notificationEmails,omitempty" tf:"notification_emails,omitempty"`

	// +kubebuilder:validation:Optional
	OracleConnector []OracleConnectorParameters `json:"oracleConnector,omitempty" tf:"oracle_connector,omitempty"`

	// Identifies the properties monitored in the stream
	// +kubebuilder:validation:Optional
	Properties []*string `json:"properties,omitempty" tf:"properties,omitempty"`

	// +kubebuilder:validation:Optional
	S3Connector []S3ConnectorParameters `json:"s3Connector,omitempty" tf:"s3_connector,omitempty"`

	// +kubebuilder:validation:Optional
	SplunkConnector []SplunkConnectorParameters `json:"splunkConnector,omitempty" tf:"splunk_connector,omitempty"`

	// The name of the stream
	// +kubebuilder:validation:Optional
	StreamName *string `json:"streamName,omitempty" tf:"stream_name,omitempty"`

	// +kubebuilder:validation:Optional
	SumologicConnector []SumologicConnectorParameters `json:"sumologicConnector,omitempty" tf:"sumologic_connector,omitempty"`
}

type DeliveryConfigurationInitParameters struct {

	// A delimiter that you use to separate data set fields in log lines
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// The format in which logs will be received
	Format *string `json:"format,omitempty" tf:"format,omitempty"`

	// The frequency of collecting logs from each uploader and sending these logs to a destination
	Frequency []FrequencyInitParameters `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// The prefix of the log file that will be send to a destination
	UploadFilePrefix *string `json:"uploadFilePrefix,omitempty" tf:"upload_file_prefix,omitempty"`

	// The suffix of the log file that will be send to a destination
	UploadFileSuffix *string `json:"uploadFileSuffix,omitempty" tf:"upload_file_suffix,omitempty"`
}

type DeliveryConfigurationObservation struct {

	// A delimiter that you use to separate data set fields in log lines
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// The format in which logs will be received
	Format *string `json:"format,omitempty" tf:"format,omitempty"`

	// The frequency of collecting logs from each uploader and sending these logs to a destination
	Frequency []FrequencyObservation `json:"frequency,omitempty" tf:"frequency,omitempty"`

	// The prefix of the log file that will be send to a destination
	UploadFilePrefix *string `json:"uploadFilePrefix,omitempty" tf:"upload_file_prefix,omitempty"`

	// The suffix of the log file that will be send to a destination
	UploadFileSuffix *string `json:"uploadFileSuffix,omitempty" tf:"upload_file_suffix,omitempty"`
}

type DeliveryConfigurationParameters struct {

	// A delimiter that you use to separate data set fields in log lines
	// +kubebuilder:validation:Optional
	FieldDelimiter *string `json:"fieldDelimiter,omitempty" tf:"field_delimiter,omitempty"`

	// The format in which logs will be received
	// +kubebuilder:validation:Optional
	Format *string `json:"format" tf:"format,omitempty"`

	// The frequency of collecting logs from each uploader and sending these logs to a destination
	// +kubebuilder:validation:Optional
	Frequency []FrequencyParameters `json:"frequency" tf:"frequency,omitempty"`

	// The prefix of the log file that will be send to a destination
	// +kubebuilder:validation:Optional
	UploadFilePrefix *string `json:"uploadFilePrefix,omitempty" tf:"upload_file_prefix,omitempty"`

	// The suffix of the log file that will be send to a destination
	// +kubebuilder:validation:Optional
	UploadFileSuffix *string `json:"uploadFileSuffix,omitempty" tf:"upload_file_suffix,omitempty"`
}

type ElasticsearchConnectorInitParameters struct {

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The PEM-formatted digital certificate you want to authenticate requests to your destination with. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the backend server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Elasticsearch bulk endpoint URL in the https://hostname.elastic-cloud.com:9243/_bulk/ format. Set indexName in the appropriate field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Elasticsearch.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The index name of the Elastic cloud where you want to store log files.
	IndexNameSecretRef v1.SecretKeySelector `json:"indexNameSecretRef" tf:"-"`

	// The Elasticsearch basic access authentication password.
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`

	// The Elasticsearch basic access authentication username.
	UserNameSecretRef v1.SecretKeySelector `json:"userNameSecretRef" tf:"-"`
}

type ElasticsearchConnectorObservation struct {

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Elasticsearch bulk endpoint URL in the https://hostname.elastic-cloud.com:9243/_bulk/ format. Set indexName in the appropriate field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Elasticsearch.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// Indicates whether mTLS is enabled or not.
	MTLS *bool `json:"mTls,omitempty" tf:"m_tls,omitempty"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`
}

type ElasticsearchConnectorParameters struct {

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	// +kubebuilder:validation:Optional
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The PEM-formatted digital certificate you want to authenticate requests to your destination with. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	// +kubebuilder:validation:Optional
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the backend server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	// +kubebuilder:validation:Optional
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The Elasticsearch bulk endpoint URL in the https://hostname.elastic-cloud.com:9243/_bulk/ format. Set indexName in the appropriate field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Elasticsearch.
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`

	// The index name of the Elastic cloud where you want to store log files.
	// +kubebuilder:validation:Optional
	IndexNameSecretRef v1.SecretKeySelector `json:"indexNameSecretRef" tf:"-"`

	// The Elasticsearch basic access authentication password.
	// +kubebuilder:validation:Optional
	PasswordSecretRef v1.SecretKeySelector `json:"passwordSecretRef" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	// +kubebuilder:validation:Optional
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`

	// The Elasticsearch basic access authentication username.
	// +kubebuilder:validation:Optional
	UserNameSecretRef v1.SecretKeySelector `json:"userNameSecretRef" tf:"-"`
}

type FrequencyInitParameters struct {

	// The time in seconds after which the system bundles log lines into a file and sends it to a destination
	IntervalInSecs *float64 `json:"intervalInSecs,omitempty" tf:"interval_in_secs,omitempty"`
}

type FrequencyObservation struct {

	// The time in seconds after which the system bundles log lines into a file and sends it to a destination
	IntervalInSecs *float64 `json:"intervalInSecs,omitempty" tf:"interval_in_secs,omitempty"`
}

type FrequencyParameters struct {

	// The time in seconds after which the system bundles log lines into a file and sends it to a destination
	// +kubebuilder:validation:Optional
	IntervalInSecs *float64 `json:"intervalInSecs" tf:"interval_in_secs,omitempty"`
}

type GcsConnectorInitParameters struct {

	// The name of the storage bucket created in Google Cloud account
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Google Cloud bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The contents of the JSON private key generated and downloaded in Google Cloud Storage account
	PrivateKeySecretRef v1.SecretKeySelector `json:"privateKeySecretRef" tf:"-"`

	// The unique ID of Google Cloud project
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`

	// The name of the service account with the storage.object.create permission or Storage Object Creator role
	ServiceAccountName *string `json:"serviceAccountName,omitempty" tf:"service_account_name,omitempty"`
}

type GcsConnectorObservation struct {

	// The name of the storage bucket created in Google Cloud account
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Google Cloud bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The unique ID of Google Cloud project
	ProjectID *string `json:"projectId,omitempty" tf:"project_id,omitempty"`

	// The name of the service account with the storage.object.create permission or Storage Object Creator role
	ServiceAccountName *string `json:"serviceAccountName,omitempty" tf:"service_account_name,omitempty"`
}

type GcsConnectorParameters struct {

	// The name of the storage bucket created in Google Cloud account
	// +kubebuilder:validation:Optional
	Bucket *string `json:"bucket" tf:"bucket,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The path to the folder within Google Cloud bucket where logs will be stored
	// +kubebuilder:validation:Optional
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The contents of the JSON private key generated and downloaded in Google Cloud Storage account
	// +kubebuilder:validation:Optional
	PrivateKeySecretRef v1.SecretKeySelector `json:"privateKeySecretRef" tf:"-"`

	// The unique ID of Google Cloud project
	// +kubebuilder:validation:Optional
	ProjectID *string `json:"projectId" tf:"project_id,omitempty"`

	// The name of the service account with the storage.object.create permission or Storage Object Creator role
	// +kubebuilder:validation:Optional
	ServiceAccountName *string `json:"serviceAccountName" tf:"service_account_name,omitempty"`
}

type HTTPSConnectorInitParameters struct {

	// Either NONE for no authentication, or BASIC for username and password authentication
	AuthenticationType *string `json:"authenticationType,omitempty" tf:"authentication_type,omitempty"`

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The digital certificate in the PEM format you want to use to authenticate requests to your destination. If you want to use mutual authentication, you need to provide both the client certificate and the client key (in the PEM format).
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the back-end server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// URL where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// Password set for custom HTTPS endpoint for authentication
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`

	// Username used for authentication
	UserNameSecretRef *v1.SecretKeySelector `json:"userNameSecretRef,omitempty" tf:"-"`
}

type HTTPSConnectorObservation struct {

	// Either NONE for no authentication, or BASIC for username and password authentication
	AuthenticationType *string `json:"authenticationType,omitempty" tf:"authentication_type,omitempty"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// URL where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// Indicates whether mTLS is enabled or not.
	MTLS *bool `json:"mTls,omitempty" tf:"m_tls,omitempty"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`
}

type HTTPSConnectorParameters struct {

	// Either NONE for no authentication, or BASIC for username and password authentication
	// +kubebuilder:validation:Optional
	AuthenticationType *string `json:"authenticationType" tf:"authentication_type,omitempty"`

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	// +kubebuilder:validation:Optional
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The digital certificate in the PEM format you want to use to authenticate requests to your destination. If you want to use mutual authentication, you need to provide both the client certificate and the client key (in the PEM format).
	// +kubebuilder:validation:Optional
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the back-end server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	// +kubebuilder:validation:Optional
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// Indicates whether the logs should be compressed
	// +kubebuilder:validation:Optional
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	// +kubebuilder:validation:Optional
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// URL where logs will be stored
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`

	// Password set for custom HTTPS endpoint for authentication
	// +kubebuilder:validation:Optional
	PasswordSecretRef *v1.SecretKeySelector `json:"passwordSecretRef,omitempty" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	// +kubebuilder:validation:Optional
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`

	// Username used for authentication
	// +kubebuilder:validation:Optional
	UserNameSecretRef *v1.SecretKeySelector `json:"userNameSecretRef,omitempty" tf:"-"`
}

type LogglyConnectorInitParameters struct {

	// The unique HTTP code for your Loggly bulk endpoint.
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Loggly bulk endpoint URL in the https://hostname.loggly.com/bulk/ format. Set the endpoint code in the authToken field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Loggly.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The tags you can use to segment and filter log events in Loggly. See Tags in the Loggly documentation.
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type LogglyConnectorObservation struct {

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Loggly bulk endpoint URL in the https://hostname.loggly.com/bulk/ format. Set the endpoint code in the authToken field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Loggly.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The tags you can use to segment and filter log events in Loggly. See Tags in the Loggly documentation.
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type LogglyConnectorParameters struct {

	// The unique HTTP code for your Loggly bulk endpoint.
	// +kubebuilder:validation:Optional
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The Loggly bulk endpoint URL in the https://hostname.loggly.com/bulk/ format. Set the endpoint code in the authToken field instead of providing it in the URL. You can use Akamaized property hostnames as endpoint URLs. See Stream logs to Loggly.
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`

	// The tags you can use to segment and filter log events in Loggly. See Tags in the Loggly documentation.
	// +kubebuilder:validation:Optional
	Tags *string `json:"tags,omitempty" tf:"tags,omitempty"`
}

type NewRelicConnectorInitParameters struct {

	// Your Log API token for your account in New Relic.
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// A New Relic endpoint URL you want to send your logs to. The endpoint URL should follow the https://<newrelic.com>/log/v1/ format format. See Introduction to the Log API https://docs.newrelic.com/docs/logs/log-api/introduction-log-api/ if you want to retrieve your New Relic endpoint URL.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`
}

type NewRelicConnectorObservation struct {

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// A New Relic endpoint URL you want to send your logs to. The endpoint URL should follow the https://<newrelic.com>/log/v1/ format format. See Introduction to the Log API https://docs.newrelic.com/docs/logs/log-api/introduction-log-api/ if you want to retrieve your New Relic endpoint URL.
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`
}

type NewRelicConnectorParameters struct {

	// Your Log API token for your account in New Relic.
	// +kubebuilder:validation:Optional
	AuthTokenSecretRef v1.SecretKeySelector `json:"authTokenSecretRef" tf:"-"`

	// The type of the resource passed in the request's custom header. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// A human-readable name for the request's custom header, containing only alphanumeric, dash, and underscore characters. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request that contains information about the client connection. For details, see Additional options in the DataStream user guide.
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector.
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// A New Relic endpoint URL you want to send your logs to. The endpoint URL should follow the https://<newrelic.com>/log/v1/ format format. See Introduction to the Log API https://docs.newrelic.com/docs/logs/log-api/introduction-log-api/ if you want to retrieve your New Relic endpoint URL.
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`
}

type OracleConnectorInitParameters struct {

	// The access key identifier used to authenticate requests to the Oracle Cloud account
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// The name of the Oracle Cloud Storage bucket
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The namespace of Oracle Cloud Storage account
	Namespace *string `json:"namespace,omitempty" tf:"namespace,omitempty"`

	// The path to the folder within your Oracle Cloud Storage bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The Oracle Cloud Storage region where bucket resides
	Region *string `json:"region,omitempty" tf:"region,omitempty"`

	// The secret access key identifier used to authenticate requests to the Oracle Cloud account
	SecretAccessKeySecretRef v1.SecretKeySelector `json:"secretAccessKeySecretRef" tf:"-"`
}

type OracleConnectorObservation struct {

	// The name of the Oracle Cloud Storage bucket
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The namespace of Oracle Cloud Storage account
	Namespace *string `json:"namespace,omitempty" tf:"namespace,omitempty"`

	// The path to the folder within your Oracle Cloud Storage bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The Oracle Cloud Storage region where bucket resides
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type OracleConnectorParameters struct {

	// The access key identifier used to authenticate requests to the Oracle Cloud account
	// +kubebuilder:validation:Optional
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// The name of the Oracle Cloud Storage bucket
	// +kubebuilder:validation:Optional
	Bucket *string `json:"bucket" tf:"bucket,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The namespace of Oracle Cloud Storage account
	// +kubebuilder:validation:Optional
	Namespace *string `json:"namespace" tf:"namespace,omitempty"`

	// The path to the folder within your Oracle Cloud Storage bucket where logs will be stored
	// +kubebuilder:validation:Optional
	Path *string `json:"path" tf:"path,omitempty"`

	// The Oracle Cloud Storage region where bucket resides
	// +kubebuilder:validation:Optional
	Region *string `json:"region" tf:"region,omitempty"`

	// The secret access key identifier used to authenticate requests to the Oracle Cloud account
	// +kubebuilder:validation:Optional
	SecretAccessKeySecretRef v1.SecretKeySelector `json:"secretAccessKeySecretRef" tf:"-"`
}

type S3ConnectorInitParameters struct {

	// The access key identifier used to authenticate requests to the Amazon S3 account
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// The name of the Amazon S3 bucket
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Amazon S3 bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The AWS region where Amazon S3 bucket resides
	Region *string `json:"region,omitempty" tf:"region,omitempty"`

	// The secret access key identifier used to authenticate requests to the Amazon S3 account
	SecretAccessKeySecretRef v1.SecretKeySelector `json:"secretAccessKeySecretRef" tf:"-"`
}

type S3ConnectorObservation struct {

	// The name of the Amazon S3 bucket
	Bucket *string `json:"bucket,omitempty" tf:"bucket,omitempty"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The path to the folder within Amazon S3 bucket where logs will be stored
	Path *string `json:"path,omitempty" tf:"path,omitempty"`

	// The AWS region where Amazon S3 bucket resides
	Region *string `json:"region,omitempty" tf:"region,omitempty"`
}

type S3ConnectorParameters struct {

	// The access key identifier used to authenticate requests to the Amazon S3 account
	// +kubebuilder:validation:Optional
	AccessKeySecretRef v1.SecretKeySelector `json:"accessKeySecretRef" tf:"-"`

	// The name of the Amazon S3 bucket
	// +kubebuilder:validation:Optional
	Bucket *string `json:"bucket" tf:"bucket,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The path to the folder within Amazon S3 bucket where logs will be stored
	// +kubebuilder:validation:Optional
	Path *string `json:"path" tf:"path,omitempty"`

	// The AWS region where Amazon S3 bucket resides
	// +kubebuilder:validation:Optional
	Region *string `json:"region" tf:"region,omitempty"`

	// The secret access key identifier used to authenticate requests to the Amazon S3 account
	// +kubebuilder:validation:Optional
	SecretAccessKeySecretRef v1.SecretKeySelector `json:"secretAccessKeySecretRef" tf:"-"`
}

type SplunkConnectorInitParameters struct {

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The digital certificate in the PEM format you want to use to authenticate requests to your destination. If you want to use mutual authentication, you need to provide both the client certificate and the client key (in the PEM format).
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the back-end server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The raw event Splunk URL where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// The Event Collector token associated with Splunk account
	EventCollectorTokenSecretRef v1.SecretKeySelector `json:"eventCollectorTokenSecretRef" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`
}

type SplunkConnectorObservation struct {

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The raw event Splunk URL where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`

	// Indicates whether mTLS is enabled or not.
	MTLS *bool `json:"mTls,omitempty" tf:"m_tls,omitempty"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`
}

type SplunkConnectorParameters struct {

	// The certification authority (CA) certificate used to verify the origin server's certificate. If the certificate is not signed by a well-known certification authority, enter the CA certificate in the PEM format for verification.
	// +kubebuilder:validation:Optional
	CACertSecretRef *v1.SecretKeySelector `json:"caCertSecretRef,omitempty" tf:"-"`

	// The digital certificate in the PEM format you want to use to authenticate requests to your destination. If you want to use mutual authentication, you need to provide both the client certificate and the client key (in the PEM format).
	// +kubebuilder:validation:Optional
	ClientCertSecretRef *v1.SecretKeySelector `json:"clientCertSecretRef,omitempty" tf:"-"`

	// The private key in the non-encrypted PKCS8 format you want to use to authenticate with the back-end server. If you want to use mutual authentication, you need to provide both the client certificate and the client key.
	// +kubebuilder:validation:Optional
	ClientKeySecretRef *v1.SecretKeySelector `json:"clientKeySecretRef,omitempty" tf:"-"`

	// Indicates whether the logs should be compressed
	// +kubebuilder:validation:Optional
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// The name of custom header passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The raw event Splunk URL where logs will be stored
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`

	// The Event Collector token associated with Splunk account
	// +kubebuilder:validation:Optional
	EventCollectorTokenSecretRef v1.SecretKeySelector `json:"eventCollectorTokenSecretRef" tf:"-"`

	// The hostname that verifies the server's certificate and matches the Subject Alternative Names (SANs) in the certificate. If not provided, DataStream fetches the hostname from the endpoint URL.
	// +kubebuilder:validation:Optional
	TLSHostname *string `json:"tlsHostname,omitempty" tf:"tls_hostname,omitempty"`
}

type SumologicConnectorInitParameters struct {

	// The unique HTTP collector code of Sumo Logic endpoint
	CollectorCodeSecretRef v1.SecretKeySelector `json:"collectorCodeSecretRef" tf:"-"`

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Sumo Logic collection endpoint where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`
}

type SumologicConnectorObservation struct {

	// Indicates whether the logs should be compressed
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	DisplayName *string `json:"displayName,omitempty" tf:"display_name,omitempty"`

	// The Sumo Logic collection endpoint where logs will be stored
	Endpoint *string `json:"endpoint,omitempty" tf:"endpoint,omitempty"`
}

type SumologicConnectorParameters struct {

	// The unique HTTP collector code of Sumo Logic endpoint
	// +kubebuilder:validation:Optional
	CollectorCodeSecretRef v1.SecretKeySelector `json:"collectorCodeSecretRef" tf:"-"`

	// Indicates whether the logs should be compressed
	// +kubebuilder:validation:Optional
	CompressLogs *bool `json:"compressLogs,omitempty" tf:"compress_logs,omitempty"`

	// Content type to pass in the log file header
	// +kubebuilder:validation:Optional
	ContentType *string `json:"contentType,omitempty" tf:"content_type,omitempty"`

	// The name of custom header passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderName *string `json:"customHeaderName,omitempty" tf:"custom_header_name,omitempty"`

	// The custom header's contents passed with the request to the destination
	// +kubebuilder:validation:Optional
	CustomHeaderValue *string `json:"customHeaderValue,omitempty" tf:"custom_header_value,omitempty"`

	// The name of the connector
	// +kubebuilder:validation:Optional
	DisplayName *string `json:"displayName" tf:"display_name,omitempty"`

	// The Sumo Logic collection endpoint where logs will be stored
	// +kubebuilder:validation:Optional
	Endpoint *string `json:"endpoint" tf:"endpoint,omitempty"`
}

// DatastreamSpec defines the desired state of Datastream
type DatastreamSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     DatastreamParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider DatastreamInitParameters `json:"initProvider,omitempty"`
}

// DatastreamStatus defines the observed state of Datastream.
type DatastreamStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        DatastreamObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// Datastream is the Schema for the Datastreams API. <no value>
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,akamai}
type Datastream struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.active) || (has(self.initProvider) && has(self.initProvider.active))",message="spec.forProvider.active is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.contractId) || (has(self.initProvider) && has(self.initProvider.contractId))",message="spec.forProvider.contractId is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.datasetFields) || (has(self.initProvider) && has(self.initProvider.datasetFields))",message="spec.forProvider.datasetFields is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.deliveryConfiguration) || (has(self.initProvider) && has(self.initProvider.deliveryConfiguration))",message="spec.forProvider.deliveryConfiguration is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.groupId) || (has(self.initProvider) && has(self.initProvider.groupId))",message="spec.forProvider.groupId is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.properties) || (has(self.initProvider) && has(self.initProvider.properties))",message="spec.forProvider.properties is a required parameter"
	// +kubebuilder:validation:XValidation:rule="!('*' in self.managementPolicies || 'Create' in self.managementPolicies || 'Update' in self.managementPolicies) || has(self.forProvider.streamName) || (has(self.initProvider) && has(self.initProvider.streamName))",message="spec.forProvider.streamName is a required parameter"
	Spec   DatastreamSpec   `json:"spec"`
	Status DatastreamStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// DatastreamList contains a list of Datastreams
type DatastreamList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []Datastream `json:"items"`
}

// Repository type metadata.
var (
	Datastream_Kind             = "Datastream"
	Datastream_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: Datastream_Kind}.String()
	Datastream_KindAPIVersion   = Datastream_Kind + "." + CRDGroupVersion.String()
	Datastream_GroupVersionKind = CRDGroupVersion.WithKind(Datastream_Kind)
)

func init() {
	SchemeBuilder.Register(&Datastream{}, &DatastreamList{})
}
